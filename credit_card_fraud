
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('creditcard.csv')

# Check for data quality
print(df.info())
print(df.describe())
print(df.isnull().sum())

# Check the balance of the target variable
print(df['Class'].value_counts())

# Data Balancing
frauds = df[df['Class'] == 1]
non_frauds = df[df['Class'] == 0].sample(n=len(frauds), random_state=1)
balanced_df = pd.concat([frauds, non_frauds])

# Train/Test Split
X = balanced_df.drop('Class', axis=1)
y = balanced_df['Class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

# Data Scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Model Training
model_svc = SVC(probability=True)
model_svc.fit(X_train, y_train)

# Model Evaluation
y_train_pred = model_svc.predict(X_train)
y_test_pred = model_svc.predict(X_test)

# Print Accuracy Scores
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)
print(f"Training Accuracy: {train_accuracy:.4f}")
print(f"Testing Accuracy: {test_accuracy:.4f}")

# Print Classification Reports
print("Training Classification Report:")
print(classification_report(y_train, y_train_pred))

print("Testing Classification Report:")
print(classification_report(y_test, y_test_pred))

# Plot ROC Curve
fpr, tpr, _ = roc_curve(y_test, model_svc.predict_proba(X_test)[:, 1])
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label='ROC Curve')
plt.plot([0, 1], [0, 1], 'k--', label='Random')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()
